# TransparNet

**TransparNet** is a neural network distillation and interpretability pipeline that compresses a deep CNN into a lightweight, interpretable decision tree, while retaining high accuracy and producing rich visual explanations of model behavior.

---

## ğŸ§  Research Question

Can we distill a high-performing convolutional neural network into a lightweight, interpretable decision tree while preserving predictive accuracy and generating actionable insight from model errors?

---

## ğŸš€ Features

- **Teacher model**: ResNet50 trained on the Imagenette dataset
- **Student model**: Decision Tree trained on PCA-reduced ResNet features
- **Distillation**: Teacher logits guide the student for fidelity and interpretability
- **Explainability**:
  - Grad-CAM, Guided Backpropagation, and PEEK entropy maps
  - Composite image overlays with attention + uncertainty
- **Error analysis**:
  - Misclassification summary with confidence scores
  - Visual diagnostics for each misclassified sample
  - Automatic t-SNE + KMeans clustering of failure modes with optimal `k` search
- **Visualization tools**:
  - Confusion matrix, t-SNE plots, and decision tree diagrams
  - Auto-saved composite image grids (no need to close plots manually)

---

## ğŸ“‚ Project Structure

```
project/
â”œâ”€â”€ app.py                       # Main entry point
â”œâ”€â”€ config.py                   # Hyperparameters & global config
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ prepare_data.py         # Dataset download, split, loaders
â”‚   â””â”€â”€ transforms.py           # Custom augmentations (e.g. Cutout)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ resnet_teacher.py       # Transfer learning model
â”‚   â”œâ”€â”€ decision_tree_student.py  # PCA + GridSearchCV
â”‚   â””â”€â”€ feature_extraction.py   # Extracts penultimate layer features
â”œâ”€â”€ analyze/
â”‚   â”œâ”€â”€ misclassifications.py   # Error visualization & summary
â”‚   â””â”€â”€ cluster_errors.py       # t-SNE + KMeans clustering of misclassifications
â”œâ”€â”€ interpret/
â”‚   â”œâ”€â”€ gradcam.py
â”‚   â”œâ”€â”€ guided_backprop.py
â”‚   â”œâ”€â”€ peek.py
â”‚   â””â”€â”€ composite.py            # Composite interpretability grid
â”œâ”€â”€ visualize/
â”‚   â”œâ”€â”€ confusion.py
â”‚   â”œâ”€â”€ decision_tree_plot.py
â”‚   â””â”€â”€ tsne.py
â””â”€â”€ utils/
    â””â”€â”€ helpers.py              # Timing, denormalization, etc.
```

---

## â–¶ï¸ Usage

Run the full pipeline:

```bash
python app.py
```

It will:
- Train the teacher
- Distill and evaluate the student
- Extract misclassifications
- Auto-generate Grad-CAM, Guided BP, PEEK visualizations
- Cluster errors via t-SNE
- Save everything to the `outputs/` directory

---

## ğŸ“Š Outputs

Youâ€™ll get:
- `outputs/decision_tree.svg` â€” student model visualization
- `outputs/misclassified_viz/` â€” Grad-CAM + PEEK overlays
- `outputs/tsne_misclassified_clusters.png` â€” clustered t-SNE plot
- `outputs/misclassified_summary.json` â€” structured error log

---

## ğŸ“ˆ Future Work

- Rank errors by entropy and confidence
- Add counterfactual perturbation analysis
- Auto-generate HTML reports or dashboards
- Integrate early exit prediction using latent activations

---

## ğŸ“„ License

MIT

---

## ğŸ¤ Acknowledgements

Built using:
- PyTorch
- torchvision
- Captum
- scikit-learn
- matplotlib
- t-SNE / KMeans
